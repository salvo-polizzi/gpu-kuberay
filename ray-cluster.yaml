apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: simple-ray-cluster
spec:
  # Use a stable Ray version (not nightly)
  rayVersion: "2.31.0"

  # -------------------------------------------------------------------
  # HEAD NODE GROUP
  # -------------------------------------------------------------------
  headGroupSpec:
    serviceType: NodePort
    rayStartParams:
      dashboard-host: "0.0.0.0"
      object-store-memory: "1073741824"  # 1GiB = safe for small clusters
    template:
      spec:
        containers:
          - name: ray-head
            # Stable, CPU-only, Py39 (best for local + PyTorch)
            image: salvo324234/ray-enhanced:2.31.0
            ports:
              - containerPort: 6379
                name: gcs
              - containerPort: 8265
                name: dashboard
              - containerPort: 10001
                name: client
            resources:
              requests:
                cpu: "1"
                memory: "2Gi"
              limits:
                cpu: "1"
                memory: "2Gi"

  # -------------------------------------------------------------------
  # DEFAULT CPU WORKER GROUP
  # -------------------------------------------------------------------
  workerGroupSpecs:
    - groupName: cpu-workers
      replicas: 1
      minReplicas: 1
      maxReplicas: 2  # allow small local autoscaling
      rayStartParams: {}
      template:
        spec:
          containers:
            - name: ray-worker
              image: salvo324234/ray-enhanced:2.31.0
              resources:
                requests:
                  cpu: "1"
                  memory: "2Gi"
                limits:
                  cpu: "1"
                  memory: "2Gi"

  # -------------------------------------------------------------------
  # OPTIONAL FUTURE GPU WORKER GROUP (disabled by default)
  # Uncomment + adjust when GPU nodes are available
  # -------------------------------------------------------------------
  # workerGroupSpecs:
  #   - groupName: gpu-workers
  #     replicas: 0
  #     minReplicas: 0
  #     maxReplicas: 4
  #     rayStartParams:
  #       num-gpus: "1"
  #     template:
  #       spec:
  #         containers:
  #         - name: ray-worker-gpu
  #           image: rayproject/ray-ml:2.31.0-gpu
  #           resources:
  #             limits:
  #               nvidia.com/gpu: 1
  #               cpu: "4"
  #               memory: "16Gi"
  #             requests:
  #               nvidia.com/gpu: 1
  #               cpu: "4"
  #               memory: "16Gi"
---
# -----------------------------------------------------------
# NodePort service to expose the Ray Client port EXTERNALLY
# -----------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: ray-client-external
spec:
  type: NodePort
  selector:
    ray.io/node-type: head
  ports:
    - name: ray-client
      protocol: TCP
      port: 10001         # inside cluster
      targetPort: 10001   # Ray head container
      nodePort: 30001     # external port (choose any free port)

